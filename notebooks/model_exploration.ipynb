{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- load train and test datasets, create TensorFlow Datasets from them\n",
    "- define main architecutre params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import skimage\n",
    "\n",
    "from src.data_utils import Dataset\n",
    "from src.network import unet_3d\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# get TF logger - set it to info for more tracking process\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_dataset = Dataset.load_dataset(\n",
    "    '../data/processed/train_dataset.pckl'\n",
    ").create_tf_dataset().shuffle(50).repeat().padded_batch(\n",
    "    batch_size=batch_size,\n",
    "    padded_shapes=([32, 128, 128, 1], [32, 128, 128, 3]))\n",
    "test_dataset = Dataset.load_dataset(\n",
    "    '../data/processed/test_dataset.pckl'\n",
    ").create_tf_dataset().shuffle(50).repeat().padded_batch(\n",
    "    batch_size=batch_size,\n",
    "    padded_shapes=([32, 128, 128, 1], [32, 128, 128, 3]))\n",
    "\n",
    "# setup dataset iterator objects, idea from:\n",
    "# http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    train_dataset.output_types,\n",
    "    train_dataset.output_shapes\n",
    ")\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:conv1: (?, 32, 128, 128, 4)\n",
      "DEBUG:tensorflow:conv2: (?, 32, 128, 128, 8)\n",
      "DEBUG:tensorflow:maxpool layer: (?, 16, 64, 64, 8)\n",
      "DEBUG:tensorflow:conv1: (?, 16, 64, 64, 8)\n",
      "DEBUG:tensorflow:conv2: (?, 16, 64, 64, 16)\n",
      "DEBUG:tensorflow:maxpool layer: (?, 8, 32, 32, 16)\n",
      "DEBUG:tensorflow:conv1: (?, 8, 32, 32, 16)\n",
      "DEBUG:tensorflow:conv2: (?, 8, 32, 32, 32)\n",
      "DEBUG:tensorflow:upconv layer: (?, 16, 64, 64, 32)\n",
      "DEBUG:tensorflow:concat layer: (?, 16, 64, 64, 16)\n",
      "DEBUG:tensorflow:up_conv layer1: (?, 16, 64, 64, 16)\n",
      "DEBUG:tensorflow:up_conv layer2 : (?, 16, 64, 64, 16)\n",
      "DEBUG:tensorflow:upconv layer: (?, 32, 128, 128, 16)\n",
      "DEBUG:tensorflow:concat layer: (?, 32, 128, 128, 8)\n",
      "DEBUG:tensorflow:up_conv layer1: (?, 32, 128, 128, 8)\n",
      "DEBUG:tensorflow:up_conv layer2 : (?, 32, 128, 128, 8)\n",
      "DEBUG:tensorflow:output layer:: (?, 32, 128, 128, 3)\n",
      "Epoch: 0, loss: 0.142, training accuracy: 72.92%\n",
      "Epoch: 0, loss: 0.142, training IOU: 24.66%\n",
      "Epoch: 50, loss: 0.051, training accuracy: 69.10%\n",
      "Epoch: 50, loss: 0.051, training IOU: 21.98%\n",
      "Epoch: 100, loss: 0.034, training accuracy: 79.10%\n",
      "Epoch: 100, loss: 0.034, training IOU: 23.13%\n",
      "Epoch: 150, loss: 0.026, training accuracy: 85.10%\n",
      "Epoch: 150, loss: 0.026, training IOU: 24.53%\n",
      "Epoch: 200, loss: 0.019, training accuracy: 68.49%\n",
      "Epoch: 200, loss: 0.019, training IOU: 26.12%\n",
      "Epoch: 250, loss: 0.020, training accuracy: 76.71%\n",
      "Epoch: 250, loss: 0.020, training IOU: 27.96%\n",
      "Epoch: 300, loss: 0.011, training accuracy: 80.81%\n",
      "Epoch: 300, loss: 0.011, training IOU: 29.42%\n",
      "Epoch: 350, loss: 0.007, training accuracy: 82.25%\n",
      "Epoch: 350, loss: 0.007, training IOU: 30.48%\n",
      "Epoch: 400, loss: 0.021, training accuracy: 93.55%\n",
      "Epoch: 400, loss: 0.021, training IOU: 31.33%\n",
      "Epoch: 450, loss: 0.012, training accuracy: 94.58%\n",
      "Epoch: 450, loss: 0.012, training IOU: 32.40%\n",
      "Epoch: 500, loss: 0.011, training accuracy: 81.63%\n",
      "Epoch: 500, loss: 0.011, training IOU: 33.18%\n",
      "Epoch: 550, loss: 0.007, training accuracy: 74.65%\n",
      "Epoch: 550, loss: 0.007, training IOU: 33.81%\n",
      "Epoch: 600, loss: 0.018, training accuracy: 94.57%\n",
      "Epoch: 600, loss: 0.018, training IOU: 34.31%\n",
      "Epoch: 650, loss: 0.019, training accuracy: 82.15%\n",
      "Epoch: 650, loss: 0.019, training IOU: 34.79%\n",
      "Epoch: 700, loss: 0.022, training accuracy: 82.77%\n",
      "Epoch: 700, loss: 0.022, training IOU: 35.29%\n",
      "Epoch: 750, loss: 0.010, training accuracy: 96.32%\n",
      "Epoch: 750, loss: 0.010, training IOU: 35.80%\n",
      "Epoch: 800, loss: 0.009, training accuracy: 96.43%\n",
      "Epoch: 800, loss: 0.009, training IOU: 36.17%\n",
      "Epoch: 850, loss: 0.024, training accuracy: 95.04%\n",
      "Epoch: 850, loss: 0.024, training IOU: 36.61%\n",
      "Epoch: 900, loss: 0.010, training accuracy: 79.81%\n",
      "Epoch: 900, loss: 0.010, training IOU: 36.95%\n",
      "Epoch: 950, loss: 0.005, training accuracy: 95.73%\n",
      "Epoch: 950, loss: 0.005, training IOU: 37.27%\n",
      "Epoch: 1000, loss: 0.016, training accuracy: 79.56%\n",
      "Epoch: 1000, loss: 0.016, training IOU: 37.58%\n",
      "Epoch: 1050, loss: 0.008, training accuracy: 97.23%\n",
      "Epoch: 1050, loss: 0.008, training IOU: 37.77%\n",
      "Epoch: 1100, loss: 0.008, training accuracy: 96.64%\n",
      "Epoch: 1100, loss: 0.008, training IOU: 38.06%\n",
      "Epoch: 1150, loss: 0.008, training accuracy: 84.16%\n",
      "Epoch: 1150, loss: 0.008, training IOU: 38.35%\n",
      "Epoch: 1200, loss: 0.008, training accuracy: 85.56%\n",
      "Epoch: 1200, loss: 0.008, training IOU: 38.59%\n",
      "Epoch: 1250, loss: 0.006, training accuracy: 84.55%\n",
      "Epoch: 1250, loss: 0.006, training IOU: 38.82%\n",
      "Epoch: 1300, loss: 0.004, training accuracy: 97.56%\n",
      "Epoch: 1300, loss: 0.004, training IOU: 39.10%\n",
      "Epoch: 1350, loss: 0.010, training accuracy: 85.34%\n",
      "Epoch: 1350, loss: 0.010, training IOU: 39.38%\n",
      "Epoch: 1400, loss: 0.008, training accuracy: 98.47%\n",
      "Epoch: 1400, loss: 0.008, training IOU: 39.59%\n",
      "Epoch: 1450, loss: 0.007, training accuracy: 89.07%\n",
      "Epoch: 1450, loss: 0.007, training IOU: 39.83%\n",
      "Epoch: 1500, loss: 0.007, training accuracy: 90.99%\n",
      "Epoch: 1500, loss: 0.007, training IOU: 40.00%\n",
      "Epoch: 1550, loss: 0.007, training accuracy: 88.54%\n",
      "Epoch: 1550, loss: 0.007, training IOU: 40.19%\n",
      "Epoch: 1600, loss: 0.009, training accuracy: 86.47%\n",
      "Epoch: 1600, loss: 0.009, training IOU: 40.38%\n",
      "Epoch: 1650, loss: 0.005, training accuracy: 88.30%\n",
      "Epoch: 1650, loss: 0.005, training IOU: 40.61%\n",
      "Epoch: 1700, loss: 0.007, training accuracy: 85.79%\n",
      "Epoch: 1700, loss: 0.007, training IOU: 40.81%\n",
      "Epoch: 1750, loss: 0.006, training accuracy: 85.99%\n",
      "Epoch: 1750, loss: 0.006, training IOU: 41.03%\n",
      "Epoch: 1800, loss: 0.009, training accuracy: 90.17%\n",
      "Epoch: 1800, loss: 0.009, training IOU: 41.24%\n",
      "Epoch: 1850, loss: 0.006, training accuracy: 94.98%\n",
      "Epoch: 1850, loss: 0.006, training IOU: 41.46%\n",
      "Epoch: 1900, loss: 0.005, training accuracy: 88.16%\n",
      "Epoch: 1900, loss: 0.005, training IOU: 41.64%\n",
      "Epoch: 1950, loss: 0.007, training accuracy: 88.28%\n",
      "Epoch: 1950, loss: 0.007, training IOU: 41.85%\n",
      "Epoch: 2000, loss: 0.008, training accuracy: 92.65%\n",
      "Epoch: 2000, loss: 0.008, training IOU: 42.06%\n",
      "Epoch: 2050, loss: 0.006, training accuracy: 96.24%\n",
      "Epoch: 2050, loss: 0.006, training IOU: 42.25%\n",
      "Epoch: 2100, loss: 0.004, training accuracy: 95.27%\n",
      "Epoch: 2100, loss: 0.004, training IOU: 42.46%\n",
      "Epoch: 2150, loss: 0.008, training accuracy: 95.91%\n",
      "Epoch: 2150, loss: 0.008, training IOU: 42.66%\n",
      "Epoch: 2200, loss: 0.019, training accuracy: 92.18%\n",
      "Epoch: 2200, loss: 0.019, training IOU: 42.87%\n",
      "Epoch: 2250, loss: 0.010, training accuracy: 99.08%\n",
      "Epoch: 2250, loss: 0.010, training IOU: 43.03%\n",
      "Epoch: 2300, loss: 0.004, training accuracy: 99.34%\n",
      "Epoch: 2300, loss: 0.004, training IOU: 43.26%\n",
      "Epoch: 2350, loss: 0.007, training accuracy: 92.15%\n",
      "Epoch: 2350, loss: 0.007, training IOU: 43.45%\n",
      "Epoch: 2400, loss: 0.005, training accuracy: 98.73%\n",
      "Epoch: 2400, loss: 0.005, training IOU: 43.65%\n",
      "Epoch: 2450, loss: 0.005, training accuracy: 98.55%\n",
      "Epoch: 2450, loss: 0.005, training IOU: 43.82%\n",
      "Epoch: 2500, loss: 0.002, training accuracy: 98.87%\n",
      "Epoch: 2500, loss: 0.002, training IOU: 44.03%\n",
      "Epoch: 2550, loss: 0.003, training accuracy: 99.24%\n",
      "Epoch: 2550, loss: 0.003, training IOU: 44.21%\n",
      "Epoch: 2600, loss: 0.004, training accuracy: 98.24%\n",
      "Epoch: 2600, loss: 0.004, training IOU: 44.40%\n",
      "Epoch: 2650, loss: 0.007, training accuracy: 99.18%\n",
      "Epoch: 2650, loss: 0.007, training IOU: 44.55%\n",
      "Epoch: 2700, loss: 0.003, training accuracy: 99.00%\n",
      "Epoch: 2700, loss: 0.003, training IOU: 44.68%\n",
      "Epoch: 2750, loss: 0.004, training accuracy: 98.24%\n",
      "Epoch: 2750, loss: 0.004, training IOU: 44.84%\n",
      "Epoch: 2800, loss: 0.004, training accuracy: 99.45%\n",
      "Epoch: 2800, loss: 0.004, training IOU: 44.99%\n",
      "Epoch: 2850, loss: 0.004, training accuracy: 99.07%\n",
      "Epoch: 2850, loss: 0.004, training IOU: 45.15%\n",
      "Epoch: 2900, loss: 0.003, training accuracy: 98.76%\n",
      "Epoch: 2900, loss: 0.003, training IOU: 45.32%\n",
      "Epoch: 2950, loss: 0.006, training accuracy: 98.12%\n",
      "Epoch: 2950, loss: 0.006, training IOU: 45.48%\n",
      "Epoch: 3000, loss: 0.003, training accuracy: 99.24%\n",
      "Epoch: 3000, loss: 0.003, training IOU: 45.63%\n",
      "Epoch: 3050, loss: 0.003, training accuracy: 99.42%\n",
      "Epoch: 3050, loss: 0.003, training IOU: 45.81%\n",
      "Epoch: 3100, loss: 0.003, training accuracy: 99.04%\n",
      "Epoch: 3100, loss: 0.003, training IOU: 45.96%\n",
      "Epoch: 3150, loss: 0.003, training accuracy: 99.20%\n",
      "Epoch: 3150, loss: 0.003, training IOU: 46.11%\n",
      "Epoch: 3200, loss: 0.005, training accuracy: 99.50%\n",
      "Epoch: 3200, loss: 0.005, training IOU: 46.25%\n",
      "Epoch: 3250, loss: 0.005, training accuracy: 99.52%\n",
      "Epoch: 3250, loss: 0.005, training IOU: 46.40%\n",
      "Epoch: 3300, loss: 0.002, training accuracy: 99.44%\n",
      "Epoch: 3300, loss: 0.002, training IOU: 46.54%\n",
      "Epoch: 3350, loss: 0.004, training accuracy: 99.67%\n",
      "Epoch: 3350, loss: 0.004, training IOU: 46.70%\n",
      "Epoch: 3400, loss: 0.006, training accuracy: 99.15%\n",
      "Epoch: 3400, loss: 0.006, training IOU: 46.83%\n",
      "Epoch: 3450, loss: 0.002, training accuracy: 98.86%\n",
      "Epoch: 3450, loss: 0.002, training IOU: 46.96%\n",
      "Epoch: 3500, loss: 0.002, training accuracy: 99.26%\n",
      "Epoch: 3500, loss: 0.002, training IOU: 47.10%\n",
      "Epoch: 3550, loss: 0.004, training accuracy: 99.54%\n",
      "Epoch: 3550, loss: 0.004, training IOU: 47.24%\n",
      "Epoch: 3600, loss: 0.002, training accuracy: 98.75%\n",
      "Epoch: 3600, loss: 0.002, training IOU: 47.37%\n",
      "Epoch: 3650, loss: 0.005, training accuracy: 99.29%\n",
      "Epoch: 3650, loss: 0.005, training IOU: 47.49%\n",
      "Epoch: 3700, loss: 0.005, training accuracy: 99.16%\n",
      "Epoch: 3700, loss: 0.005, training IOU: 47.60%\n",
      "Epoch: 3750, loss: 0.003, training accuracy: 99.32%\n",
      "Epoch: 3750, loss: 0.003, training IOU: 47.72%\n",
      "Epoch: 3800, loss: 0.005, training accuracy: 99.59%\n",
      "Epoch: 3800, loss: 0.005, training IOU: 47.84%\n",
      "Epoch: 3850, loss: 0.002, training accuracy: 99.37%\n",
      "Epoch: 3850, loss: 0.002, training IOU: 47.97%\n",
      "Epoch: 3900, loss: 0.002, training accuracy: 99.24%\n",
      "Epoch: 3900, loss: 0.002, training IOU: 48.09%\n",
      "Epoch: 3950, loss: 0.003, training accuracy: 98.91%\n",
      "Epoch: 3950, loss: 0.003, training IOU: 48.20%\n",
      "Epoch: 4000, loss: 0.003, training accuracy: 99.34%\n",
      "Epoch: 4000, loss: 0.003, training IOU: 48.31%\n",
      "Epoch: 4050, loss: 0.003, training accuracy: 99.28%\n",
      "Epoch: 4050, loss: 0.003, training IOU: 48.43%\n",
      "Epoch: 4100, loss: 0.003, training accuracy: 99.42%\n",
      "Epoch: 4100, loss: 0.003, training IOU: 48.54%\n",
      "Epoch: 4150, loss: 0.004, training accuracy: 99.57%\n",
      "Epoch: 4150, loss: 0.004, training IOU: 48.64%\n",
      "Epoch: 4200, loss: 0.002, training accuracy: 99.39%\n",
      "Epoch: 4200, loss: 0.002, training IOU: 48.74%\n",
      "Epoch: 4250, loss: 0.002, training accuracy: 99.35%\n",
      "Epoch: 4250, loss: 0.002, training IOU: 48.86%\n",
      "Epoch: 4300, loss: 0.003, training accuracy: 99.46%\n",
      "Epoch: 4300, loss: 0.003, training IOU: 48.96%\n",
      "Epoch: 4350, loss: 0.002, training accuracy: 99.42%\n",
      "Epoch: 4350, loss: 0.002, training IOU: 49.06%\n",
      "Epoch: 4400, loss: 0.003, training accuracy: 99.34%\n",
      "Epoch: 4400, loss: 0.003, training IOU: 49.16%\n",
      "Epoch: 4450, loss: 0.004, training accuracy: 99.59%\n",
      "Epoch: 4450, loss: 0.004, training IOU: 49.25%\n",
      "Epoch: 4500, loss: 0.008, training accuracy: 99.31%\n",
      "Epoch: 4500, loss: 0.008, training IOU: 49.36%\n",
      "Epoch: 4550, loss: 0.003, training accuracy: 99.70%\n",
      "Epoch: 4550, loss: 0.003, training IOU: 49.45%\n",
      "Epoch: 4600, loss: 0.003, training accuracy: 99.67%\n",
      "Epoch: 4600, loss: 0.003, training IOU: 49.56%\n",
      "Epoch: 4650, loss: 0.002, training accuracy: 99.52%\n",
      "Epoch: 4650, loss: 0.002, training IOU: 49.66%\n",
      "Epoch: 4700, loss: 0.003, training accuracy: 99.52%\n",
      "Epoch: 4700, loss: 0.003, training IOU: 49.77%\n",
      "Epoch: 4750, loss: 0.005, training accuracy: 98.88%\n",
      "Epoch: 4750, loss: 0.005, training IOU: 49.88%\n",
      "Epoch: 4800, loss: 0.003, training accuracy: 99.65%\n",
      "Epoch: 4800, loss: 0.003, training IOU: 49.97%\n",
      "Epoch: 4850, loss: 0.002, training accuracy: 99.43%\n",
      "Epoch: 4850, loss: 0.002, training IOU: 50.06%\n",
      "Epoch: 4900, loss: 0.005, training accuracy: 99.45%\n",
      "Epoch: 4900, loss: 0.005, training IOU: 50.12%\n",
      "Epoch: 4950, loss: 0.004, training accuracy: 99.16%\n",
      "Epoch: 4950, loss: 0.004, training IOU: 50.20%\n",
      "Epoch: 5000, loss: 0.001, training accuracy: 99.15%\n",
      "Epoch: 5000, loss: 0.001, training IOU: 50.28%\n",
      "Epoch: 5050, loss: 0.001, training accuracy: 99.36%\n",
      "Epoch: 5050, loss: 0.001, training IOU: 50.37%\n",
      "Epoch: 5100, loss: 0.002, training accuracy: 99.44%\n",
      "Epoch: 5100, loss: 0.002, training IOU: 50.46%\n",
      "Epoch: 5150, loss: 0.002, training accuracy: 99.29%\n",
      "Epoch: 5150, loss: 0.002, training IOU: 50.54%\n",
      "Epoch: 5200, loss: 0.002, training accuracy: 99.43%\n",
      "Epoch: 5200, loss: 0.002, training IOU: 50.63%\n",
      "Epoch: 5250, loss: 0.002, training accuracy: 99.47%\n",
      "Epoch: 5250, loss: 0.002, training IOU: 50.72%\n",
      "Epoch: 5300, loss: 0.004, training accuracy: 99.55%\n",
      "Epoch: 5300, loss: 0.004, training IOU: 50.81%\n",
      "Epoch: 5350, loss: 0.003, training accuracy: 99.63%\n",
      "Epoch: 5350, loss: 0.003, training IOU: 50.89%\n",
      "Epoch: 5400, loss: 0.002, training accuracy: 99.40%\n",
      "Epoch: 5400, loss: 0.002, training IOU: 50.98%\n",
      "Epoch: 5450, loss: 0.002, training accuracy: 99.23%\n",
      "Epoch: 5450, loss: 0.002, training IOU: 51.07%\n",
      "Epoch: 5500, loss: 0.002, training accuracy: 99.48%\n",
      "Epoch: 5500, loss: 0.002, training IOU: 51.15%\n",
      "Epoch: 5550, loss: 0.002, training accuracy: 99.55%\n",
      "Epoch: 5550, loss: 0.002, training IOU: 51.23%\n",
      "Epoch: 5600, loss: 0.002, training accuracy: 99.51%\n",
      "Epoch: 5600, loss: 0.002, training IOU: 51.32%\n",
      "Epoch: 5650, loss: 0.003, training accuracy: 99.72%\n",
      "Epoch: 5650, loss: 0.003, training IOU: 51.40%\n",
      "Epoch: 5700, loss: 0.002, training accuracy: 99.39%\n",
      "Epoch: 5700, loss: 0.002, training IOU: 51.49%\n",
      "Epoch: 5750, loss: 0.002, training accuracy: 99.45%\n",
      "Epoch: 5750, loss: 0.002, training IOU: 51.57%\n",
      "Epoch: 5800, loss: 0.003, training accuracy: 99.41%\n",
      "Epoch: 5800, loss: 0.003, training IOU: 51.64%\n",
      "Epoch: 5850, loss: 0.002, training accuracy: 99.48%\n",
      "Epoch: 5850, loss: 0.002, training IOU: 51.72%\n",
      "Epoch: 5900, loss: 0.003, training accuracy: 99.41%\n",
      "Epoch: 5900, loss: 0.003, training IOU: 51.80%\n",
      "Epoch: 5950, loss: 0.001, training accuracy: 99.44%\n",
      "Epoch: 5950, loss: 0.001, training IOU: 51.88%\n",
      "Epoch: 6000, loss: 0.002, training accuracy: 99.53%\n",
      "Epoch: 6000, loss: 0.002, training IOU: 51.96%\n",
      "Epoch: 6050, loss: 0.001, training accuracy: 99.02%\n",
      "Epoch: 6050, loss: 0.001, training IOU: 52.03%\n",
      "Epoch: 6100, loss: 0.002, training accuracy: 99.39%\n",
      "Epoch: 6100, loss: 0.002, training IOU: 52.11%\n",
      "Epoch: 6150, loss: 0.005, training accuracy: 99.10%\n",
      "Epoch: 6150, loss: 0.005, training IOU: 52.16%\n",
      "Epoch: 6200, loss: 0.003, training accuracy: 98.93%\n",
      "Epoch: 6200, loss: 0.003, training IOU: 52.21%\n",
      "Epoch: 6250, loss: 0.004, training accuracy: 99.63%\n",
      "Epoch: 6250, loss: 0.004, training IOU: 52.28%\n",
      "Epoch: 6300, loss: 0.002, training accuracy: 99.39%\n",
      "Epoch: 6300, loss: 0.002, training IOU: 52.34%\n",
      "Epoch: 6350, loss: 0.002, training accuracy: 99.67%\n",
      "Epoch: 6350, loss: 0.002, training IOU: 52.42%\n",
      "Epoch: 6400, loss: 0.003, training accuracy: 99.68%\n",
      "Epoch: 6400, loss: 0.003, training IOU: 52.49%\n",
      "Epoch: 6450, loss: 0.002, training accuracy: 99.62%\n",
      "Epoch: 6450, loss: 0.002, training IOU: 52.56%\n",
      "Epoch: 6500, loss: 0.002, training accuracy: 99.77%\n",
      "Epoch: 6500, loss: 0.002, training IOU: 52.63%\n",
      "Epoch: 6550, loss: 0.002, training accuracy: 99.58%\n",
      "Epoch: 6550, loss: 0.002, training IOU: 52.70%\n",
      "Epoch: 6600, loss: 0.001, training accuracy: 99.48%\n",
      "Epoch: 6600, loss: 0.001, training IOU: 52.78%\n",
      "Epoch: 6650, loss: 0.002, training accuracy: 99.72%\n",
      "Epoch: 6650, loss: 0.002, training IOU: 52.85%\n",
      "Epoch: 6700, loss: 0.002, training accuracy: 99.70%\n",
      "Epoch: 6700, loss: 0.002, training IOU: 52.92%\n",
      "Epoch: 6750, loss: 0.002, training accuracy: 99.56%\n",
      "Epoch: 6750, loss: 0.002, training IOU: 52.99%\n",
      "Epoch: 6800, loss: 0.005, training accuracy: 98.96%\n",
      "Epoch: 6800, loss: 0.005, training IOU: 53.06%\n",
      "Epoch: 6850, loss: 0.005, training accuracy: 99.54%\n",
      "Epoch: 6850, loss: 0.005, training IOU: 53.12%\n",
      "Epoch: 6900, loss: 0.003, training accuracy: 99.45%\n",
      "Epoch: 6900, loss: 0.003, training IOU: 53.18%\n",
      "Epoch: 6950, loss: 0.001, training accuracy: 99.27%\n",
      "Epoch: 6950, loss: 0.001, training IOU: 53.24%\n",
      "Average test set accuracy over 1000 iterations is 98.79%\n",
      "Average test set IOU over 1000 iterations is 53.30%\n",
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# create the neural network model\n",
    "train_phase = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "logits = unet_3d(next_element[0], training=train_phase, depth=3, n_base_filters=4)\n",
    "\n",
    "# add the optimizer and weigthed softmax loss\n",
    "# see https://stackoverflow.com/a/44563055\n",
    "class_weights = np.array([0.00408978, 0.70013423, 0.295776])\n",
    "class_weights = tf.cast(tf.constant(class_weights), tf.float32)\n",
    "# deduce weights for batch samples based on their true label\n",
    "class_weights = tf.reduce_sum(tf.cast(next_element[0], tf.float32) * class_weights, axis=-1)\n",
    "loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=next_element[1], weights=class_weights)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "# get accuracy\n",
    "prediction = tf.argmax(logits, axis=-1)\n",
    "labels = tf.argmax(next_element[1], -1)\n",
    "equality = tf.equal(prediction, labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "# get mean iou\n",
    "iou, conf_mat = tf.metrics.mean_iou(\n",
    "    labels=labels, \n",
    "    predictions=tf.cast(prediction, tf.int32),\n",
    "    num_classes=3\n",
    ")\n",
    "\n",
    "# setup variables for training\n",
    "train_n = 70\n",
    "test_n = 10\n",
    "epochs = 100\n",
    "\n",
    "# run the training\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(training_init_op)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i in range(epochs * train_n):\n",
    "    # how to run tf.metrics, idea taken from: https://stackoverflow.com/a/46414395\n",
    "    l, _, acc, _, _ = sess.run([loss, train_op, accuracy, iou, conf_mat], feed_dict={train_phase:True})\n",
    "    miou = sess.run([iou])\n",
    "    if i % 50 == 0:\n",
    "        print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, l, acc * 100))\n",
    "        print(\"Epoch: {}, loss: {:.3f}, training IOU: {:.2f}%\".format(i, l, miou[0] * 100))\n",
    "\n",
    "\n",
    "# re-initialize the iterator, but this time with test data\n",
    "sess.run(test_init_op)\n",
    "test_iters = epochs * test_n\n",
    "avg_acc = 0\n",
    "avg_miou = 0\n",
    "for i in range(test_iters):\n",
    "    acc, miou = sess.run([accuracy, iou], feed_dict={train_phase:False})\n",
    "    avg_acc += acc\n",
    "    avg_miou += miou\n",
    "print(\"Average test set accuracy over {} iterations is {:.2f}%\".format(test_iters, (avg_acc / test_iters) * 100))\n",
    "print(\"Average test set IOU over {} iterations is {:.2f}%\".format(test_iters, (avg_miou / test_iters) * 100))\n",
    "\n",
    "save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pkg_resources.extern.packaging failed: Traceback (most recent call last):\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/importlib/__init__.py\", line 147, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module pkg_resources._vendor.packaging not in sys.modules\n",
      "]\n",
      "[autoreload of pkg_resources.extern.six failed: Traceback (most recent call last):\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/importlib/__init__.py\", line 147, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module pkg_resources._vendor.six not in sys.modules\n",
      "]\n",
      "[autoreload of pkg_resources._vendor.packaging.__about__ failed: Traceback (most recent call last):\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'pkg_resources._vendor.packaging' not in sys.modules\n",
      "]\n",
      "[autoreload of pkg_resources.extern.pyparsing failed: Traceback (most recent call last):\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/importlib/__init__.py\", line 147, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module pkg_resources._vendor.pyparsing not in sys.modules\n",
      "]\n",
      "[autoreload of pkg_resources.extern.appdirs failed: Traceback (most recent call last):\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/daniel/.virtualenvs/tf/lib/python3.5/importlib/__init__.py\", line 147, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module pkg_resources._vendor.appdirs not in sys.modules\n",
      "]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-68fad47d8553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnew_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/bs2_d3_f4_e200/model.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnew_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tf/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1532\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('../models/bs2_d3_f4_e200/model.ckpt.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(test_init_op)\n",
    "y_pred, y_true = sess.run([prediction, labels], feed_dict={train_phase: False})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "sess.run(test_init_op)\n",
    "y_pred, y_true = sess.run([prediction, labels], feed_dict={train_phase: False})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADWCAYAAADfCUmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEMZJREFUeJzt3XusZWV9xvHvIwNYAeVmJshwGYTUUNMWnFoaiSVKFRCEJkqoVkaLTky81lIENYGmXir1nrS2o1BGpVxEFLRiQYq1l4DMIHdERuQykwG0ICIYdPTXP/Y6ujnOmXNmX84e3vP9JJO9Lu9a613vvOc5a7977bNSVUiS2vWUSVdAkjReBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMM+ie5JPsmqSSLuvnLkiyfh+OekeRz4z6ONBdJ/jvJayddj62VQT8PktyV5KdJfpLk/iTnJNlxHMeqqiOratUc63T4OOogTUnyT12//0mSnyX5ed/8ZQPu871JzhlxVZtm0M+fY6pqR+BgYBnwnukF0uP/iZpRVW+sqh27vv9+4IKp+ao6cnr5qXemGi1DZZ5V1XrgMuC5AEm+keR9Sf4HeAzYL8kzkpyVZEOS9d0VzDZd+W2SfCjJD5PcCbysf//d/l7fN/+GJLcleSTJrUkOTvJZYG/gy92V1Sld2UOS/G+SHyW5IclhfftZmuQ/u/1cAew+1obSgpBk/27o8XVJ7gEuT3J4krumlVuX5LAkRwOnAK/u+u6avmJLu/77SJKvJdl1Hk9lq2bQz7MkewFHAd/uW/waYAWwE3A3cA6wEdgfOAh4CTAV3m8Aju6WLwNesZljvRI4AzgReDrwcuD/quo1wD107zKq6swkewL/BrwX2BU4GfhCkmd2u/tXYA29gP9bYOyfA2hBeSHwHKZduExXVV8BzgTO7fru8/pWv4pev1wM7AC8Y0x1fdLxbdL8+VKSjcDD9AL1/X3rzqmqWwCSLKb3i2Dnqvop8GiSj9L7RfDPwPHAx6rq3q78B4DDZjjm64Ezq+rabn7tZur358BXq+qr3fwVSVYDRyW5CvgD4PCqehz4ZpIvb8G5S7M5vaoeA0gy6D7Oqqo7un18nt4FkjDo59NxVfX1Gdbd2ze9D7AtsKGvwz+lr8yzppW/ezPH3Av43hzrtw/wyiTH9C3bFriqO+ZDVfXotOPuNcd9S7O5d/Yis7qvb/oxYCw3PDwZGfRbh/4/IXov8Diwe1Vt3ETZDTwxYPfezH7vBZ49h2NOlf1sVb1hesEk+wC7JNmhL+z33sQ+pIHUE/+M7qPA06Zmug9od+svPl/1aoVj9FuZqtoAXA58OMnTkzwlybOT/HFX5ELgrUmWJNkFOHUzu/s0cHKS53V39OzfhTbA/cB+fWU/BxyT5KXdB75P7T78WlJVdwOrgb9Jsl2SQ4FjkMbjO8BOXV/cFjid3rvLKfcD+2aIMZ6FxqDfOp0IbAfcCjwEXATs0a37FPDvwA3AdcDFM+2kqj4PvI/eB6mPAF+i90ErwAeA93R32JzcjfkfC7wL+AG9K/y/5td95FXAHwIP0vvB+8woTlSarqoeAt4CrALW0+tz/cMyF9D7+Xgwybfmv4ZPPvHBI5LUNq/oJalxBr0kNW5sQZ/kiCS3J1mbZHMfGEqSxmgsY/Td1/W/C/wJsA64Fvizqrp15AeTJG3WuO6jfz6wtqruBEhyPr07OjYZ9En8RFiSttwPq+qZsxUa19DNnjzxm27rumW/kmRFktXd1+wlSVtuc9+M/5WJfTO2qlYCK8Erekkap3Fd0a/niV/TX9ItkyTNs3EF/bXAAd3fMN8OOAG4dEzHkiRtxliGbqpqY5I30/uq/jbA2VN/hleSNL+2ij+B4Bi9JA1kTVUtm62Q34yVpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxg0c9En2SnJVkluT3JLkbd3yXZNckeSO7nWX0VVXkrSlhrmi3wj8VVUdCBwCvCnJgcCpwJVVdQBwZTcvSZqQgYO+qjZU1XXd9CPAbcCewLHAqq7YKuC4YSspSRrcolHsJMm+wEHANcDiqtrQrboPWDzDNiuAFaM4viRpZkN/GJtkR+ALwNur6sf966qqgNrUdlW1sqqWzeUJ5pKkwQ0V9Em2pRfy51bVxd3i+5Ps0a3fA3hguCpKkoYxzF03Ac4Cbquqj/StuhRY3k0vBy4ZvHqSpGGlN7oywIbJocB/ATcBv+wWv4veOP2FwN7A3cDxVfXgLPsarBKStLCtmcvw98BBP0oGvSQNZE5B7zdjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXFDB32SbZJ8O8lXuvmlSa5JsjbJBUm2G76akqRBjeKK/m3AbX3zHwQ+WlX7Aw8BJ43gGJKkAQ0V9EmWAC8DPt3NB3gRcFFXZBVw3DDHkCQNZ9gr+o8BpwC/7OZ3A35UVRu7+XXAnpvaMMmKJKuTrB6yDpKkzRg46JMcDTxQVWsG2b6qVlbVsrk8wVySNLhFQ2z7AuDlSY4Cngo8Hfg4sHOSRd1V/RJg/fDVlCQNauAr+qo6raqWVNW+wAnAf1TVq4GrgFd0xZYDlwxdS0nSwMZxH/07gXckWUtvzP6sMRxDkjRHqapJ14Ekk6+EJD35rJnL55x+M1aSGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaN1TQJ9k5yUVJvpPktiR/lGTXJFckuaN73WVUlZUkbblhr+g/Dnytqp4D/B5wG3AqcGVVHQBc2c1LkiZk4GfGJnkGcD2wX/XtJMntwGFVtSHJHsA3quq3Z9mXz4yVpC039mfGLgV+APxLkm8n+XSSHYDFVbWhK3MfsHiIY0iShjRM0C8CDgY+WVUHAY8ybZimu9Lf5NV6khVJVidZPUQdJEmzGCbo1wHrquqabv4iesF/fzdkQ/f6wKY2rqqVVbVsLm87JEmDGzjoq+o+4N4kU+PvLwZuBS4FlnfLlgOXDFVDSdJQFg25/VuAc5NsB9wJvI7eL48Lk5wE3A0cP+QxJElDGPium5FWwrtuJGkQY7/rRpL0JGDQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaN1TQJ/nLJLckuTnJeUmemmRpkmuSrE1yQfeYQUnShAwc9En2BN4KLKuq5wLbACcAHwQ+WlX7Aw8BJ42iopKkwQw7dLMI+K0ki4CnARuAFwEXdetXAccNeQxJ0hAGDvqqWg98CLiHXsA/DKwBflRVG7ti64A9h62kJGlwwwzd7AIcCywFngXsAByxBduvSLI6yepB6yBJmt2iIbY9HPh+Vf0AIMnFwAuAnZMs6q7qlwDrN7VxVa0EVnbb1hD1kCRtxjBj9PcAhyR5WpIALwZuBa4CXtGVWQ5cMlwVJUnDGGaM/hp6H7peB9zU7Wsl8E7gHUnWArsBZ42gnpKkAaVq8qMmDt1I0kDWVNWy2Qr5zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY2bNeiTnJ3kgSQ39y3bNckVSe7oXnfplifJJ5KsTXJjkoPHWXlJ0uzmckV/DnDEtGWnAldW1QHAld08wJHAAd2/FcAnR1NNSdKgZg36qvom8OC0xccCq7rpVcBxfcs/Uz1XAzsn2WNUlZUkbblBx+gXV9WGbvo+YHE3vSdwb1+5dd2y35BkRZLVSVYPWAdJ0hwsGnYHVVVJaoDtVgIrAQbZXpI0N4Ne0d8/NSTTvT7QLV8P7NVXbkm3TJI0IYMG/aXA8m56OXBJ3/ITu7tvDgEe7hvikSRNwKxDN0nOAw4Ddk+yDjgd+DvgwiQnAXcDx3fFvwocBawFHgNeN4Y6S5K2QKomPzzuGL0kDWRNVS2brZDfjJWkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGzRr0Sc5O8kCSm/uW/X2S7yS5MckXk+zct+60JGuT3J7kpeOquCRpbuZyRX8OcMS0ZVcAz62q3wW+C5wGkORA4ATgd7pt/jHJNiOrrSRpi80a9FX1TeDBacsur6qN3ezVwJJu+ljg/Kp6vKq+T+8h4c8fYX0lSVtoFGP0fwFc1k3vCdzbt25dt+w3JFmRZHWS1SOogyRpBouG2TjJu4GNwLlbum1VrQRWdvupYeohSZrZwEGf5LXA0cCLq2oqqNcDe/UVW9ItkyRNyEBDN0mOAE4BXl5Vj/WtuhQ4Icn2SZYCBwDfGr6akqRBzXpFn+Q84DBg9yTrgNPp3WWzPXBFEoCrq+qNVXVLkguBW+kN6bypqn4xrspLkmaXX4+6TLASjtFL0iDWVNWy2Qr5zVhJapxBL0mNM+glqXEGvSQ1bqgvTI3QD4FHu9eFbHdsA7AdwDYA22DK5tphn7nsYKu46wYgyeq5fHrcMtugx3awDcA2mDKKdnDoRpIaZ9BLUuO2pqBfOekKbAVsgx7bwTYA22DK0O2w1YzRS5LGY2u6opckjYFBL0mNm3jQJzmie5D42iSnTro+8ynJXUluSnL91JO2kuya5Iokd3Svu0y6nqM0w8PmN3nO6flE1zduTHLw5Go+WjO0wxlJ1nf94fokR/WtO61rh9uTvHQytR6tJHsluSrJrUluSfK2bvmC6Q+baYPR9oWqmtg/YBvge8B+wHbADcCBk6zTPJ//XcDu05adCZzaTZ8KfHDS9RzxOb8QOBi4ebZzBo6i95jKAIcA10y6/mNuhzOAkzdR9sDuZ2N7YGn3M7PNpM9hBG2wB3BwN70T8N3uXBdMf9hMG4y0L0z6iv75wNqqurOqfgacT+8B4wvZscCqbnoVcNwE6zJytYmHzTPzOR8LfKZ6rgZ2TrLH/NR0vGZoh5kcC5xfVY9X1feBtfR+dp7UqmpDVV3XTT8C3EbvGdMLpj9spg1mMlBfmHTQz/lh4o0q4PIka5Ks6JYtrqoN3fR9wOLJVG1ezXTOC7F/vLkblji7b9iu+XZIsi9wEHANC7Q/TGsDGGFfmHTQL3SHVtXBwJHAm5K8sH9l9d6rLaj7XxfiOff5JPBs4PeBDcCHJ1ud+ZFkR+ALwNur6sf96xZKf9hEG4y0L0w66Bf0w8Sran33+gDwRXpvwe6fejvavT4wuRrOm5nOeUH1j6q6v6p+UVW/BD7Fr9+SN9sOSbalF3DnVtXF3eIF1R821Qaj7guTDvprgQOSLE2yHXACvQeMNy/JDkl2mpoGXgLcTO/8l3fFlgOXTKaG82qmc74UOLG72+IQ4OG+t/TNmTbe/Kf0+gP02uGEJNsnWQocAHxrvus3auk9cPos4Laq+kjfqgXTH2Zqg5H3ha3gU+ej6H3S/D3g3ZOuzzye9370Pj2/Abhl6tyB3YArgTuArwO7TrquIz7v8+i9Ff05vfHFk2Y6Z3p3V/xD1zduApZNuv5jbofPdud5Y/cDvUdf+Xd37XA7cOSk6z+iNjiU3rDMjcD13b+jFlJ/2EwbjLQv+CcQJKlxkx66kSSNmUEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGvf/0jQrTMqt1MMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcac45a6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcac45a6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "p=y_pred[i] \n",
    "t=y_true[i]\n",
    "ys = np.concatenate((p, t), axis=2)\n",
    "fig, ax = plt.subplots()\n",
    "for i, scan in enumerate(ys):\n",
    "    plt.imshow(scan, cmap=plt.cm.bone)\n",
    "    plt.title('Predicted                                   Truth')\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
